{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edddd8e1-278a-401e-abd9-8957cbbdd75a",
   "metadata": {},
   "source": [
    "# Classifying long vs short life in LFP/Graphite cells üë¨\n",
    "\n",
    "### In this notebook, we are using binary logistic regression to classify long vs short lived cells, based on the efforts of Severson et. al in \"Data-driven prediction of battery cycle life before capacity degradation\" üíª\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcefabe5-b3f8-4f19-84ad-12c8ab5f29a1",
   "metadata": {},
   "source": [
    "## We must again first load the data üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f78257fb-e559-4374-8942-f38f5c16f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_batches(paths):\n",
    "    all_cells = {}\n",
    "    for path in paths:\n",
    "        with open(path, 'rb') as f:\n",
    "            batch = pickle.load(f)\n",
    "        all_cells.update(batch)\n",
    "    return all_cells\n",
    "\n",
    "batch_paths = ['../data/batch1.pkl', '../data/batch2.pkl', '../data/batch3.pkl']\n",
    "cells = load_batches(batch_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a947a993-6496-412b-b113-af0f7ddd9b5e",
   "metadata": {},
   "source": [
    "## Now, we need to make and train our models üë®‚Äçüçº\n",
    "\n",
    "To get started, we'll load functions from our other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c4ca3dc-35c4-4300-9a65-4ed680a2e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update your function slightly to return the namespace\n",
    "def load_functions_from_ipynb(path, function_names, namespace=None):\n",
    "    import nbformat, ast\n",
    "\n",
    "    if namespace is None:\n",
    "        namespace = {}\n",
    "\n",
    "    with open(path) as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type != \"code\":\n",
    "            continue\n",
    "\n",
    "        parsed = ast.parse(cell.source)\n",
    "        for node in parsed.body:\n",
    "            if isinstance(node, ast.FunctionDef) and node.name in function_names:\n",
    "                exec(compile(ast.Module([node], []), filename=\"<ast>\", mode=\"exec\"), namespace)\n",
    "\n",
    "    return namespace\n",
    "\n",
    "functions_from_other_notebook = ['extract_features_simple', \n",
    "                                 'extract_feautures_full', \n",
    "                                 'create_X_y_arrays',\n",
    "                                 'split_and_fit']\n",
    "\n",
    "ns = load_functions_from_ipynb(r\"1_Cycle-life-prediction-using-interpretable-ML.ipynb\", functions_from_other_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee1fcaf-d513-410d-a932-e8ba77071723",
   "metadata": {},
   "source": [
    "Now, we need to create the feature and target arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc74c447-014e-45a6-a234-d540e5b3ab26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m X_simple, y \u001b[38;5;241m=\u001b[39m \u001b[43mns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreate_X_y_arrays\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mextract_features_simple\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcells\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m X_full \u001b[38;5;241m=\u001b[39m ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_X_y_arrays\u001b[39m\u001b[38;5;124m'\u001b[39m](ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextract_features_full\u001b[39m\u001b[38;5;124m'\u001b[39m], cells)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m<ast>:25\u001b[0m, in \u001b[0;36mcreate_X_y_arrays\u001b[0;34m(extract_features, cells)\u001b[0m\n",
      "File \u001b[0;32m<ast>:9\u001b[0m, in \u001b[0;36mextract_features_simple\u001b[0;34m(cell, max_cycle)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_simple, y = ns['create_X_y_arrays'](ns['extract_features_simple'], cells)\n",
    "X_full = ns['create_X_y_arrays'](ns['extract_features_full'], cells)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15160608-9260-4b34-ab36-c8d71c70d1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01b46d-fd52-41eb-90ac-c71ef3fe8054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
